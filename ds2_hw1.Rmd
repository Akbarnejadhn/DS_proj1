---
title: "project1"
author: "Hana Akbarnejad"
date: "2/23/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


library(tidyverse)
library(viridis)
library(ggplot2)
library(readr)
library(modelr)
library(ISLR)
library(glmnet)
library(caret)
library(corrplot)
library(plotmo)
library(pls)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

In this exercise, we will predict solubility of compounds using their chemical structures. We will use traing and test data, fit linear, Ridge, Lasso, and principle component regression models and discuss the results.

```{r import_data, include=FALSE}

train_data = read_csv("solubility_train.csv") %>% 
  janitor::clean_names() %>% 
  na.omit()

test_data = read_csv("solubility_test.csv") %>% 
  janitor::clean_names() %>% 
  na.omit()
```


```{r cv, echo=FALSE}

set.seed(1)

# setting up x matrix and y for train and test data
x_train = model.matrix(solubility ~ ., train_data)[,-1]
y_train = train_data$solubility

x_test = model.matrix(solubility ~ ., test_data)[,-1]
y_test = test_data$solubility

# need to define a train control, reampling method specified as repeated Cv
# turnGrid: candidates for tuning parameter
# I chose to pre-process!
# "train" here is resampling method and is different from the next train :)
# I will use it every where needed!

train_control = trainControl(method = "repeatedcv", number = 10, repeats = 5)

```


### (a)

Fit a linear model using least squares on the training data and calculate the mean square error using the test data.

```{r a}

set.seed(1)

# fit lm model using training data
lm_fit = train(x_train, y_train,
              method = "lm",
              trControl = train_control)

summary(lm_fit)

# predict model using training model and test data
test_pred = predict(lm_fit, test_data)
summary(test_pred)

# calculating MSE using training and test models
# mean((y_pred - y_test)^2)
mse = mean((test_pred - test_data$solubility)^2)
```

The mean square error using the test data is `r round(mse, 3)`.

### (b)

In this part, we want to choose $\lambda$ by cross-validation and fit a ridge regression model on the training data and find out the test error.

We first form predictor matrix, then fit a ridge regression model. We use cross validation to choose the optimal value of $\lambda$. We use $\alpha=0$ which is the ridge penalty to obtain $\lambda$ using *cv.glmnet* function. Alternatively, we can use Use *train()* function from *caret* package to fit Ridge regression:

**trying to do Ridge regression using caret**
```{r ridge_caret}

set.seed(1)

ridge_fit = train(x_train, y_train,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = 0,
                                         lambda = exp(seq(-5, 5, length = 100))),
            preProc = c("center", "scale"),
            trControl = train_control)

# plot the parameters over RMSE to choose the best option
plot(ridge_fit, xTrans = function(x) log(x))

# best lambda!
ridge_lambda = ridge_fit$bestTune

# summary of coefficients in Ridge regression
coef(ridge_fit$finalModel,ridge_fit$bestTune$lambda)

# MSE from Ridge
pred_ridge_fit = predict(ridge_fit, newdata = test_data)

ridge_mse = mean((pred_ridge_fit - y_test)^2)

```

We can see that the optimum lambda chosen is `r round(ridge_fit$bestTune, 3)`.

To compute the test error, we need to predict the test data using the model we have built and then use that to compute the MSE. We can see that the test error obtained from this model is `r round(ridge_mse, 3)`.


### (c)

In this part, we want to choose $\lambda$ by cross-validation and fit a Lasso regression model on the training data and find out the test error.

```{r lasso}

set.seed(1)
# fitting lasso regression, we should set alpha as 1
lasso_fit = train(x_train, y_train,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = 1,
                                         lambda = exp(seq(-10, 2, length = 100))),
            preProc = c("center", "scale"),
            trControl = train_control)

# plotting
plot(lasso_fit, xTrans = function(x) log(x))

# best lambda!
lasso_lambda = lasso_fit$bestTune

# summary of coefficients in Lasso regression
lasso_coeff = coef(lasso_fit$finalModel,lasso_fit$bestTune$lambda)

# MSE from Lasso
pred_lasso_fit = predict(lasso_fit, newdata = test_data)
lasso_mse = mean((pred_lasso_fit - y_test)^2)

# non-zero coefficients

coeff_df = as.data.frame(as.matrix(lasso_coeff))

nonzero_coeff = coeff_df %>% 
  filter(coeff_df[1] != 0) %>% 
  nrow()
```

We can see that the $\lambda =$ obtained from cross validation is `r round(lasso_lambda, 3)`, the test error is `r round(lasso_mse, 3)`, and that there are `r nonzero_coeff`.

### (d)

In this part, we want to choose M by cross-validation, and fit a principle component regression model on the training data. We furthur want to compute the test error:

```{r pcr}

set.seed(1)

# fitting PCR
pcr_fit = train(x_train, y_train, method = "pcr",
                tuneGrid = data.frame(ncomp = 1:228),
                trControl = train_control,
                preProc = c("center", "scale"))

trans = preProcess(x_train, method = c("center", "scale"))

pred_pcr = predict(pcr_fit$finalModel, newdata = predict(trans, x_test),
ncomp = pcr_fit$bestTune$ncomp)

pcr_mse = mean((y_test - pred_pcr)^2)

pcr_m = pcr_fit$bestTune

ggplot(pcr_fit, highlight = TRUE) + theme_bw()

```

We can observe that the value of M chosen by cross validation is `r pcr_m`, and the test error is `r round(pcr_mse, 3)`.

### (e)

```{r summary}

round(mse, 3)
round(ridge_mse, 3)
round(lasso_mse, 3)
round(pcr_mse, 3)

ridge_fit$bestTune
lasso_fit$bestTune
```

Lasso is the best, lowest MSE?
lambda for lasso much lower than ridge (0.004 vs 0.126)

### (f)

In this section we want to select one model which is the between linear, Ridge, Lasso, and PC regressions to predict solubility:

```{r}

resamp = resamples(list(pcr = pcr_fit, lasso = lasso_fit, ridge = ridge_fit, lm = lm_fit))
summary(resamp)

parallelplot(resamp, metric = "RMSE")
bwplot(resamp, metric = "RMSE")
```

